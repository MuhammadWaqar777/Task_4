{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3724379,
     "status": "error",
     "timestamp": 1754912809556,
     "user": {
      "displayName": "Muhammad Waqar",
      "userId": "05537177784745369598"
     },
     "user_tz": -300
    },
    "id": "1h8fdYlTrgA0",
    "outputId": "3333bb81-8cbb-4157-beca-cb3cfe51a5d5"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch accelerate\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def is_safe_query(user_input):\n",
    "    unsafe_keywords = [\"suicide\", \"self-harm\", \"overdose\", \"poison\", \"kill\"]\n",
    "    return not any(keyword in user_input.lower() for keyword in unsafe_keywords)\n",
    "\n",
    "def health_chatbot():\n",
    "    print(\"ðŸ¤– General Health Assistant (Not a doctor, for educational purposes only!)\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Bot: Goodbye! Stay healthy. ðŸ©º\")\n",
    "            break\n",
    "\n",
    "        if not is_safe_query(user_input):\n",
    "            print(\"Bot: I cannot provide advice on that topic. Please seek help from a medical professional.\")\n",
    "            continue\n",
    "\n",
    "        prompt = f\"Act like a helpful medical assistant. Give safe, general health information. Avoid dangerous advice.\\nUser: {user_input}\\nAssistant:\"\n",
    "\n",
    "        response = chatbot(\n",
    "            prompt,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        answer = response[0]['generated_text'].split(\"Assistant:\")[-1].strip()\n",
    "        print(f\"Bot: {answer}\")\n",
    "\n",
    "# Run chatbot\n",
    "health_chatbot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXgfhskLsCDt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDEQO+WJ6h/9pg05PMln0Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
